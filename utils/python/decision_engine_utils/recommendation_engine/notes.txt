Frontend will send request to Query model deployment endpoint. 
Query model will have Transformer with preprocess and postprocess. 
In preprocess, it will retrieve only item_ids argument from the input and send to model predict. 
Then postprocess will receive query embedding. 
To this embedding, we add session context from the request input and send to ranking model. 
Ranking model has transformer too. It takes query embedding and retrieves N nearest neighbours (item ids). 
For each of these item ids we add item features and send to ranking model together with session context. 
Ranking model postprocess receives item ids with scores, we add item features again 
(for frontend to easily show items properties) and return to user.
So its like a chain: 
query enpoint -> query preproc -> query model -> query postproc -> ranking endpoint -> ranking preproc -> ranking model -> ranking postproc -> user